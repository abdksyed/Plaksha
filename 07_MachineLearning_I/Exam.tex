\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\graphicspath{ {./images/} }

\title{ML Exam}
\author{Syed Abdul Khader}
\date{27 December 2022}

\begin{document}

\maketitle

\section*{Problem 1}

For $r = 1, 2, 3, 4, 5$ - Find the best rank-$r$ approximation of
\newline

\begin{center}
\begin{tabular}{ c | c | c | c | c | c }
    0.7820 & 0.7190 & 0.5210 & 0.6280 & 0.8640 & 0.5630\\
    1.0750 & 0.8780 & 0.6030 & 0.9290 & 1.0630 & 0.8520\\
    1.1250 & 0.7250 & 0.4340 & 1.0860 & 0.8930 & 1.0280\\
    0.6600 & 0.7770 & 0.6130 & 0.4290 & 0.9210 & 0.3540\\
    0.3600 & 0.3080 & 0.2160 & 0.3020 & 0.3710 & 0.2750\\
    1.2270 & 0.8830 & 0.5680 & 1.1300 & 1.0790 & 1.0560\\
    0.5520 & 0.3850 & 0.2430 & 0.5160 & 0.4710 & 0.4840\\
\end{tabular}
\end{center}

Find the $L^2-norm$ error between the approximation and the original matrix. If we were to design an efficient value of $r$, which $r$ will we choose and why?

\newline

\subsection*{Solution}

We know the Singular Value Decomposition for a Matrix A is given by
$$
A=U \Sigma V^T
$$
To get the values $U, \Sigma$ and $V$ we use the following

$$
A^TA = VΣU^TUΣV^T = V \Sigma^2 V^T (U.U^T = I)
$$

$$
AA^T = UΣV^TVΣU^T = U \Sigma^2 U^T (V.V^T = I)
$$

$$
A^TA = 
\begin{right}
\begin{bmatrix}
5.408 & 4.241 & 2.857 & 4.775 & 5.148 & 4.408\\
4.241 & 3.44  & 2.357 & 3.677 & 4.166 & 3.377\\
2.857 & 2.357 & 1.628 & 2.454 & 2.851 & 2.247\\
4.775 & 3.677 & 2.454 & 4.255 & 4.469 & 3.939\\
5.148 & 4.166 & 2.851 & 4.469 & 5.046 & 4.106\\
4.408 & 3.377 & 2.247 & 3.939 & 4.106 & 3.65\\
\end{bmatrix}
\end{right}
$$

Characteristic Equation of $A^TA$ is given as $|A^TA - \lambda I| = 0$

$$
\begin{vmatrix}
5.408-\lambda & 4.241 & 2.857 & 4.775 & 5.148 & 4.408\\
4.241 & 3.44-\lambda  & 2.357 & 3.677 & 4.166 & 3.377\\
2.857 & 2.357 & 1.628-\lambda & 2.454 & 2.851 & 2.247\\
4.775 & 3.677 & 2.454 & 4.255-\lambda & 4.469 & 3.939\\
5.148 & 4.166 & 2.851 & 4.469 & 5.046-\lambda & 4.106\\
4.408 & 3.377 & 2.247 & 3.939 & 4.106 & 3.65-\lambda\\
\end{vmatrix} = 0
$$

The Eigen Values of the above system are
$$
[22.99959, 0.427182, 0.00000079133, 0.0000003815, 0.0000001551, 0.0000001101855]
$$

The corresponding eigen vectors for the above eigen values is transposed to get the final $V^T$ matrix.

$$
V^T = 
\begin{bmatrix}
-0.484 & -0.383 & -0.259 & -0.426 & -0.465 & -0.393\\
-0.161 &  0.389 &  0.44  & -0.447 &  0.429 & -0.496\\
-0.626 & -0.384 & -0.016 &  0.305 &  0.593 &  0.126\\
-0.039 &  0.432 & -0.839 & -0.147 &  0.293 & -0.007\\
-0.498 &  0.575 &  0.096 &  0.501 & -0.39  & -0.091\\
0.312  & -0.192 & -0.159 &  0.504 &  0.102 & -0.759\\
\end{bmatrix}
$$

The $\Sigma$ Matrix is a diagonal matrix, with the values having square root of the eigen values.



$$
\Sigma = 
\begin{bmatrix}
4.79578 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0.65359 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0.00088 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0.00061 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0.00039 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0.00033 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
\end{bmatrix}
$$

Now for $AA^T$,

$$
AA^T = 
\begin{right}
\begin{bmatrix}
2.857 & 3.767 & 3.659 & 2.658 & 1.280 & 4.126 & 1.838\\
3.767 & 5.009 & 4.941 & 3.440 & 1.696 & 5.533 & 2.470\\
3.659 & 4.941 & 5.013 & 3.224 & 1.664 & 5.543 & 2.484\\
2.658 & 3.440 & 3.224 & 2.572 & 1.177 & 3.696 & 1.638\\
1.280 & 1.696 & 1.664 & 1.177 & 0.575&  1.868 & 0.833\\
4.126 & 5.533 & 5.543 & 3.696 & 1.868 & 6.164 & 2.757\\
1.838 & 2.470 & 2.484 & 1.638 & 0.833 & 2.757 & 1.234\\
\end{bmatrix}
\end{right}
$$

Characteristic Equation of $AA^T$ is given as $|AA^T - \lambda I| = 0$

The Eigen Values are same as we got in the above case, and the corresponding Eigen Vector forms the $U$ matrix.

$$
U = 
\begin{bmatrix}
-0.35  & 0.298  & 0.24   & -0.177 & -0.077 & -0.734 & -0.395\\
-0.467 & 0.082  & 0.421  & 0.676  & 0.288  & 0.077  & 0.229\\
-0.462 & -0.488 & -0.362 & 0.139  & 0.018  & 0.192  & -0.601\\
-0.318 & 0.756  & -0.26  & -0.17  & 0.004  & 0.469  & -0.102\\
-0.158 & 0.069  & -0.711 & 0.297  & -0.162 & -0.412 & 0.425\\
-0.517 & -0.258 & 0.215  & -0.391 & -0.525 & 0.138  & 0.415\\
-0.231 & -0.153 & -0.126 & -0.471 & 0.78   & -0.101 & 0.259\\
\end{bmatrix}
$$


For Rank 1 Approximation we take only the first eigen value in the $\Sigma$ matrix and get the new $A_1$ which is Rank 1 approximation of $A$

$$
\Sigma = 
\begin{bmatrix}
4.79578 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
\end{bmatrix}
$$

$$
A_1 = 
U \Sigma V^T
$$ 

$$
A_1 = 
\begin{bmatrix}
0.813 & 0.643 & 0.435 & 0.715 & 0.78  & 0.659\\
1.084 & 0.857 & 0.58  & 0.953 & 1.04  & 0.878\\
1.074 & 0.849 & 0.574 & 0.944 & 1.03  & 0.87\\
0.739 & 0.585 & 0.395 & 0.65  & 0.709 & 0.599\\
0.367 & 0.29  & 0.196 & 0.322 & 0.352 & 0.297\\
1.2   & 0.949 & 0.642 & 1.055 & 1.151 & 0.972\\
0.536 & 0.424 & 0.287 & 0.471 & 0.514 & 0.434\\
\end{bmatrix}
$$

$L^2-norm$ between original $A$ and Rank-1 approximation $A_1$ is given by $\sqrt{\sum_{i}{n}\sum_{j}{n} |a_{i,j}|^2}$ 

$$
|A - A_1|_2 = 0.6535
$$

Similarly Rank-2 Approximation is:

$$
\Sigma = 
\begin{bmatrix}
4.79578 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0.65359 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
\end{bmatrix}
$$

$$
A_2 = 
U \Sigma V^T
$$ 

$$
A_2 = 
\begin{bmatrix}
0.782 & 0.719 & 0.521 & 0.628 & 0.864 & 0.563\\
1.075 & 0.878 & 0.603 & 0.929 & 1.063 & 0.852\\
1.125 & 0.725 & 0.434 & 1.086 & 0.893 & 1.028\\
0.66  & 0.777 & 0.613 & 0.429 & 0.921 & 0.354\\
0.36  & 0.308 & 0.216 & 0.302 & 0.371 & 0.275\\
1.227 & 0.883 & 0.568 & 1.13  & 1.079 & 1.056\\
0.552 & 0.385 & 0.243 & 0.516 & 0.471 & 0.484\\
\end{bmatrix}
$$

$$
|A - A_2|_2 = 0.001199
$$

Similarly Rank-3 Approximation is:

$$
\Sigma = 
\begin{bmatrix}
4.79578 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0.65359 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 00088 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
\end{bmatrix}
$$

$$
A_3 = 
U \Sigma V^T
$$ 

$$
A_3 = 
\begin{bmatrix}
0.782 & 0.719 & 0.521 & 0.628 & 0.864 & 0.563\\
1.075 & 0.878 & 0.603 & 0.929 & 1.063 & 0.852\\
1.125 & 0.725 & 0.434 & 1.086 & 0.893 & 1.028\\
0.66  & 0.777 & 0.613 & 0.429 & 0.921 & 0.354\\
0.36  & 0.308 & 0.216 & 0.302 & 0.371 & 0.275\\
1.227 & 0.883 & 0.568 & 1.13  & 1.079 & 1.056\\
0.552 & 0.385 & 0.243 & 0.516 & 0.471 & 0.484\\
\end{bmatrix}
$$

$$
|A - A_3|_2 = 0.000804
$$

Similarly Rank-4 Approximation is:

$$
\Sigma = 
\begin{bmatrix}
4.79578 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0.65359 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 00088 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0.00061 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
\end{bmatrix}
$$

$$
A_4 = 
U \Sigma V^T
$$ 

$$
A_4 = 
\begin{bmatrix}
0.782 & 0.719 & 0.521 & 0.628 & 0.864 & 0.563\\
1.075 & 0.878 & 0.603 & 0.929 & 1.063 & 0.852\\
1.125 & 0.725 & 0.434 & 1.086 & 0.893 & 1.028\\
0.66  & 0.777 & 0.613 & 0.429 & 0.921 & 0.354\\
0.36  & 0.308 & 0.216 & 0.302 & 0.371 & 0.275\\
1.227 & 0.883 & 0.568 & 1.13  & 1.079 & 1.056\\
0.552 & 0.385 & 0.243 & 0.516 & 0.471 & 0.484\\
\end{bmatrix}
$$

$$
|A - A_4|_2 = 0.000515
$$

Similarly Rank-5 Approximation is:

$$
\Sigma = 
\begin{bmatrix}
4.79578 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0.65359 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 00088 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0.00061 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0.00039 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0 & 0\\
\end{bmatrix}
$$

$$
A_5 = 
U \Sigma V^T
$$ 

$$
A_5 = 
\begin{bmatrix}
0.782 & 0.719 & 0.521 & 0.628 & 0.864 & 0.563\\
1.075 & 0.878 & 0.603 & 0.929 & 1.063 & 0.852\\
1.125 & 0.725 & 0.434 & 1.086 & 0.893 & 1.028\\
0.66  & 0.777 & 0.613 & 0.429 & 0.921 & 0.354\\
0.36  & 0.308 & 0.216 & 0.302 & 0.371 & 0.275\\
1.227 & 0.883 & 0.568 & 1.13  & 1.079 & 1.056\\
0.552 & 0.385 & 0.243 & 0.516 & 0.471 & 0.484\\
\end{bmatrix}
$$

$$
|A - A_5|_2 = 0.000331
$$

\includegraphics{Plot.png}

Here we can see that, when $r=1$, the $L^2-norm$ is high, whereas as $r=2$, the error decreases drastically and doesn't reduce much with increase in $r$. Hence the efficient rank is $r=2$

\section*{Problem 2}

\end{document}
