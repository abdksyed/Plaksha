{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'The': 3,\n",
       "         'cat': 3,\n",
       "         'is': 2,\n",
       "         'in': 1,\n",
       "         'the': 3,\n",
       "         'box': 3,\n",
       "         '.': 3,\n",
       "         'likes': 1,\n",
       "         'over': 1})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(word_tokenize(\"\"\"The cat is in the box. The cat likes the box. \n",
    "The box is over the cat.\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'cat': 3, 'box': 3, 'likes': 1}), [('cat', 3), ('box', 3)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"The cat is in the box. The cat likes the box. \n",
    "The box is over the cat.\"\"\"\n",
    "\n",
    "tokens = [w for w in word_tokenize(text.lower()) if w.isalpha()]\n",
    "\n",
    "no_stops = [t for t in tokens if t not in stopwords.words('english')]\n",
    "\n",
    "Counter(no_stops), Counter(no_stops).most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0,\n",
       " 'a': 1,\n",
       " 'about': 2,\n",
       " 'aliens': 3,\n",
       " 'and': 4,\n",
       " 'movie': 5,\n",
       " 'spaceship': 6,\n",
       " 'the': 7,\n",
       " 'was': 8,\n",
       " '!': 9,\n",
       " 'i': 10,\n",
       " 'liked': 11,\n",
       " 'really': 12,\n",
       " ',': 13,\n",
       " 'action': 14,\n",
       " 'awesome': 15,\n",
       " 'boring': 16,\n",
       " 'but': 17,\n",
       " 'characters': 18,\n",
       " 'scenes': 19,\n",
       " 'alien': 20,\n",
       " 'awful': 21,\n",
       " 'films': 22,\n",
       " 'hate': 23,\n",
       " 'cool': 24,\n",
       " 'is': 25,\n",
       " 'space': 26,\n",
       " 'more': 27,\n",
       " 'please': 28}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_documents = [\"The movie was about a spaceship and aliens.\",\n",
    "           \"I really liked the movie!\",\n",
    "           \"Awesome action scenes, but boring characters.\",\n",
    "           \"The movie was awful! I hate alien films.\",\n",
    "           \"Space is cool! I liked the movie.\",\n",
    "           \"More space films, please!\"]\n",
    "\n",
    "tokenized_docs = [word_tokenize(doc.lower()) for doc in my_documents]\n",
    "dictionary = Dictionary(tokenized_docs)\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n",
      "[(5, 1), (7, 1), (9, 1), (10, 1), (11, 1), (12, 1)]\n",
      "[(0, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)]\n",
      "[(0, 1), (5, 1), (7, 1), (8, 1), (9, 1), (10, 1), (20, 1), (21, 1), (22, 1), (23, 1)]\n",
      "[(0, 1), (5, 1), (7, 1), (9, 1), (10, 1), (11, 1), (24, 1), (25, 1), (26, 1)]\n",
      "[(9, 1), (13, 1), (22, 1), (26, 1), (27, 1), (28, 1)]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "for c in corpus:\n",
    "    print(c)\n",
    "# List of Lists\n",
    "# Each list is a document\n",
    "# Each tuple is a word(tokenId in corpus) and its count(frequency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf-idf with gensim\n",
    "\n",
    "* Term frequency - inverse document frequency.\n",
    "* Allows to determine the most important words in each document\n",
    "* Each corpus may have shared words beyond just stopwords\n",
    "* These words should be down-weighted in importance\n",
    "* Example from astronomy: \"star\" is a common word, but it is not as important as \"neutron star\" or \"black hole\"\n",
    "* Ensure most common words don't show up as key words\n",
    "* Keeps document specific frequence words weighted high\n",
    "\n",
    "$$\n",
    "tfidf(t,d,D) = tf(t,d) \\times idf(t,D)\n",
    "$$\n",
    "$$\n",
    "w_{i,j} = tf_{i,j} \\times log(\\frac{N}{df_i})\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$w_{i,j}$ is the weight of token $i$ in document $j$.  \n",
    "$tf_{i,j}$ is the term frequency of token $i$ in document $j$.  \n",
    "$df_i$ is the number of documents that contain token $i$.  \n",
    "$N$ is the total number of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0.1746298276735174),\n",
       " (7, 0.1746298276735174),\n",
       " (9, 0.1746298276735174),\n",
       " (10, 0.29853166221463673),\n",
       " (11, 0.47316148988815415),\n",
       " (12, 0.7716931521027908)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfModel(corpus)\n",
    "tfidf[corpus[1]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e88b31e8812fab8a8c3167b74bd89ae6a958182eff846370ba1060052b7892b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
